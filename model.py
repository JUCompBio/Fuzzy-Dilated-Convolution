import torch
from torch import nn
from rrdb import ResidualResidualDenseBlock
from fuzzy import ChannelSpatialAttention


class RRDB_Fuzzy(nn.Module):
    def __init__(self, out_dim=512, out_channels=1):
        super(RRDB_Fuzzy, self).__init__()
        self.conv2d_1 = nn.Conv2d(3, 64, 5, 2, 2)
        self.bn_1 = nn.BatchNorm2d(64)
        self.activation = nn.ReLU()
        self.rrdb_1 = ResidualResidualDenseBlock(64, 16)
        self.bn_2 = nn.BatchNorm2d(64)
        self.conv2d_2 = nn.Conv2d(64, 128, 3, 2, 1)
        self.bn_3 = nn.BatchNorm2d(128)
        self.rrdb_2 = ResidualResidualDenseBlock(128, 32)
        self.bn_4 = nn.BatchNorm2d(128)
        self.conv2d_3 = nn.Conv2d(128, 256, 3, 2, 1)
        self.bn_5 = nn.BatchNorm2d(256)
        self.rrdb_3 = ResidualResidualDenseBlock(256, 64)
        self.bn_6 = nn.BatchNorm2d(256)
        self.conv2d_4 = nn.Conv2d(256, 512, 3, 2, 1)
        self.bn_7 = nn.BatchNorm2d(512)
        self.spatial_att = ChannelSpatialAttention(512, 32, 3, [1, 3, 5, 7], [1, 3, 5, 7])
        self.bn_8 = nn.BatchNorm2d(512)
        self.conv2d_3x3_out_1 = nn.Conv2d(1024, 256, (3, 3), 1, 1)
        self.bn_9 = nn.BatchNorm2d(256)
        self.upsample_1 = nn.Upsample(out_dim // 4, mode="bilinear")
        self.conv2d_3x3_out_2 = nn.Conv2d(256, 256, (3, 3), 1, 1)
        self.bn_10 = nn.BatchNorm2d(256)
        self.upsample_2 = nn.Upsample(out_dim, mode="bilinear")
        self.conv2d_1x1_out = nn.Conv2d(256, out_channels, (1, 1))
        self.conv2d_3x3_out_3 = nn.Conv2d(out_channels, out_channels, (3, 3), 1, 1)

    def forward(self, x):
        x = self.conv2d_1(x)
        x = self.activation(x)
        x = self.bn_1(x)
        x = self.rrdb_1(x)
        x = self.activation(x)
        x = self.bn_2(x)
        x = self.conv2d_2(x)
        x = self.activation(x)
        x = self.bn_3(x)
        x = self.rrdb_2(x)
        x = self.activation(x)
        x = self.bn_4(x)
        x = self.conv2d_3(x)
        x = self.activation(x)
        x = self.bn_5(x)
        x = self.rrdb_3(x)
        x = self.activation(x)
        x = self.bn_6(x)
        x = self.conv2d_4(x)
        x = self.activation(x)
        x1 = self.bn_7(x)
        x = self.spatial_att(x1)
        x = self.activation(x)
        x = self.bn_8(x)
        x = torch.concat([x, x1], dim=1)
        x = self.conv2d_3x3_out_1(x)
        x = self.activation(x)
        x = self.bn_9(x)
        x = self.upsample_1(x)
        x = self.conv2d_3x3_out_2(x)
        x = self.activation(x)
        x = self.bn_10(x)
        x = self.upsample_2(x)
        x = self.conv2d_1x1_out(x)
        x = self.conv2d_3x3_out_3(x)
        return x
